{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9429405,"sourceType":"datasetVersion","datasetId":5728480}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers\n!pip install -q sentencepiece\n!pip install -q jiwer\n!pip install -q datasets\n!pip install -q evaluate\n!pip install -q -U accelerate\n!pip install -q matplotlib\n!pip install -q protobuf==3.20.1\n!pip install -q tensorboard","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-18T18:54:50.236725Z","iopub.execute_input":"2024-09-18T18:54:50.237544Z","iopub.status.idle":"2024-09-18T18:56:53.344130Z","shell.execute_reply.started":"2024-09-18T18:54:50.237464Z","shell.execute_reply":"2024-09-18T18:56:53.342965Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport evaluate\nimport numpy as np\nimport pandas as pd\nimport glob as glob\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as F\nimport random\nfrom PIL import Image\nfrom zipfile import ZipFile\nfrom tqdm.notebook import tqdm\nfrom dataclasses import dataclass\nfrom torch.utils.data import Dataset\nfrom urllib.request import urlretrieve\nfrom transformers import (\n    VisionEncoderDecoderModel,\n    TrOCRProcessor,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    default_data_collator,\n    GenerationConfig\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:53.346718Z","iopub.execute_input":"2024-09-18T18:56:53.347069Z","iopub.status.idle":"2024-09-18T18:56:53.354975Z","shell.execute_reply.started":"2024-09-18T18:56:53.347032Z","shell.execute_reply":"2024-09-18T18:56:53.354054Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IAMDataset(Dataset):\n    def __init__(self, root_dir, df, processor, max_target_length=128):\n        self.root_dir = root_dir\n        self.df = df\n        self.processor = processor\n        self.max_target_length = max_target_length\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # get file name + text\n        file_name = self.df['file_name'][idx]\n        text = self.df['text'][idx]\n        # prepare image (i.e. resize + normalize)\n        image = Image.open(os.path.join(self.root_dir, file_name)).convert(\"RGB\")\n        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n        # add labels (input_ids) by encoding the text\n        labels = self.processor.tokenizer(text,\n                                          padding=\"max_length\",\n                                          max_length=self.max_target_length).input_ids\n        # important: make sure that PAD tokens are ignored by the loss function\n        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n\n        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n        return encoding","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:53.356435Z","iopub.execute_input":"2024-09-18T18:56:53.356867Z","iopub.status.idle":"2024-09-18T18:56:53.367353Z","shell.execute_reply.started":"2024-09-18T18:56:53.356831Z","shell.execute_reply":"2024-09-18T18:56:53.366467Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\ntrain_dataset = IAMDataset(root_dir='/kaggle/input/amount-in-french/fr/train',\n                           df=train_df,\n                           processor=processor)\neval_dataset = IAMDataset(root_dir='/kaggle/input/amount-in-french/fr/valid',\n                           df=valid_df,\n                           processor=processor)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:53.370352Z","iopub.execute_input":"2024-09-18T18:56:53.370700Z","iopub.status.idle":"2024-09-18T18:56:53.382427Z","shell.execute_reply.started":"2024-09-18T18:56:53.370663Z","shell.execute_reply":"2024-09-18T18:56:53.381505Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of training examples:\", len(train_dataset))\nprint(\"Number of validation examples:\", len(eval_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:53.383762Z","iopub.execute_input":"2024-09-18T18:56:53.384053Z","iopub.status.idle":"2024-09-18T18:56:53.408409Z","shell.execute_reply.started":"2024-09-18T18:56:53.384020Z","shell.execute_reply":"2024-09-18T18:56:53.407480Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoding = train_dataset[0]\nfor k,v in encoding.items():\n    print(k, v.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:53.409719Z","iopub.execute_input":"2024-09-18T18:56:53.410138Z","iopub.status.idle":"2024-09-18T18:56:53.425311Z","shell.execute_reply.started":"2024-09-18T18:56:53.410092Z","shell.execute_reply":"2024-09-18T18:56:53.424137Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open(os.path.join(train_dataset.root_dir, train_df['file_name'][0])).convert(\"RGB\")\nimage","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:53.426910Z","iopub.execute_input":"2024-09-18T18:56:53.427317Z","iopub.status.idle":"2024-09-18T18:56:53.441469Z","shell.execute_reply.started":"2024-09-18T18:56:53.427274Z","shell.execute_reply":"2024-09-18T18:56:53.440359Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = encoding['labels']\nlabels[labels == -100] = processor.tokenizer.pad_token_id\nlabel_str = processor.decode(labels, skip_special_tokens=True)\nprint(label_str)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:53.442912Z","iopub.execute_input":"2024-09-18T18:56:53.443262Z","iopub.status.idle":"2024-09-18T18:56:54.232975Z","shell.execute_reply.started":"2024-09-18T18:56:53.443213Z","shell.execute_reply":"2024-09-18T18:56:54.231870Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-stage1\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:54.234250Z","iopub.execute_input":"2024-09-18T18:56:54.234674Z","iopub.status.idle":"2024-09-18T18:56:54.240208Z","shell.execute_reply.started":"2024-09-18T18:56:54.234626Z","shell.execute_reply":"2024-09-18T18:56:54.239089Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set special tokens used for creating the decoder_input_ids from the labels\nmodel.config.decoder_start_token_id = processor.tokenizer.cls_token_id\nmodel.config.pad_token_id = processor.tokenizer.pad_token_id\n# make sure vocab size is set correctly\nmodel.config.vocab_size = model.config.decoder.vocab_size\n# set beam search parameters\nmodel.config.eos_token_id = processor.tokenizer.sep_token_id\nmodel.config.max_length = 64\nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 4","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:56:54.244508Z","iopub.execute_input":"2024-09-18T18:56:54.245101Z","iopub.status.idle":"2024-09-18T18:57:01.872725Z","shell.execute_reply.started":"2024-09-18T18:56:54.245065Z","shell.execute_reply":"2024-09-18T18:57:01.871672Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\nper_device_train_batch_size=6\nsteps_per_epoch = len(train_dataset) // per_device_train_batch_size\n\ntraining_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"steps\",\n    per_device_train_batch_size=6,\n    per_device_eval_batch_size=6,\n    fp16=True,\n    output_dir=\"./\",\n    logging_steps=steps_per_epoch // 10,  # Log 10 times per epoch\n    save_steps=steps_per_epoch,  # Save once per epoch\n    eval_steps=steps_per_epoch,  # Evaluate once per epoch\n    num_train_epochs=60  # Train for 100 epochs\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:57:01.874132Z","iopub.execute_input":"2024-09-18T18:57:01.874517Z","iopub.status.idle":"2024-09-18T18:57:01.880827Z","shell.execute_reply.started":"2024-09-18T18:57:01.874437Z","shell.execute_reply":"2024-09-18T18:57:01.879806Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cer_metric = evaluate.load(\"cer\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:57:01.882102Z","iopub.execute_input":"2024-09-18T18:57:01.882426Z","iopub.status.idle":"2024-09-18T18:57:01.894525Z","shell.execute_reply.started":"2024-09-18T18:57:01.882390Z","shell.execute_reply":"2024-09-18T18:57:01.893563Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n\n    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"cer\": cer}","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:57:01.895859Z","iopub.execute_input":"2024-09-18T18:57:01.896522Z","iopub.status.idle":"2024-09-18T18:57:02.471440Z","shell.execute_reply.started":"2024-09-18T18:57:01.896463Z","shell.execute_reply":"2024-09-18T18:57:02.470547Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator\n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    tokenizer=processor.feature_extractor,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    data_collator=default_data_collator,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-18T19:17:56.673480Z","iopub.execute_input":"2024-09-18T19:17:56.673870Z","iopub.status.idle":"2024-09-18T19:17:56.710085Z","shell.execute_reply.started":"2024-09-18T19:17:56.673835Z","shell.execute_reply":"2024-09-18T19:17:56.709108Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}